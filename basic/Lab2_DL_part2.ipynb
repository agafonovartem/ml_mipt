{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Copy of agafonov Lab2_DL_part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0zoiNccZmvU",
        "colab_type": "text"
      },
      "source": [
        "## Lab 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4-xND_mZmvW",
        "colab_type": "text"
      },
      "source": [
        "### Part 2. Almost Shakespeare (2.0 points)\n",
        "\n",
        "В этой части задания мы научимся генерировать текст с помощью нейронных сетей. Конкретнее, обучим нейронную сеть на сонетах Шекспира и попросим нейросеть написать свой сонет.\n",
        "\n",
        "Генерация текста обычно включает в себя следующие шаги:\n",
        "    \n",
        "1. Загрузка данных.\n",
        "2. Создание словарей слов/символов.\n",
        "3. Препроцессинг данных.\n",
        "4. Обучение модели (нейросети).\n",
        "5. Генерация нового текста.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BIbnfvCZmvX",
        "colab_type": "text"
      },
      "source": [
        "#### Часть 1. Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mOSyjkuZmvY",
        "colab_type": "text"
      },
      "source": [
        "Для начала загрузим данные. Файл с сонетами Шекспира доступен по [ссылке](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). Кроме того, он находится рядом с этим ноутбуком (`sonnetes.txt`).\n",
        "\n",
        "Базовая предобработка уже сделана: текст состоит непосредственно из поэм Шекспира и названий/номеров глав, все техническая информация удалена."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCw0DB13ZmvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "913byJ93Zmvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "  \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START:TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J1yYlpVZmvd",
        "colab_type": "text"
      },
      "source": [
        "Так как в этот раз мы хотим научиться предсказывать текст, понизим сложность задачи и приведем текст к нижнему регистру.\n",
        "\n",
        "В настоящий момент переменная `text` представляет собой список из строк. Объедините все строки в одну и приведите к нижнему регистру. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLnklVDdZmve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0176653b-75ef-4f7e-88df-ffba721561c1"
      },
      "source": [
        "# Объедините все строки в одну и приведите к нижнему регистру.\n",
        "# Результат запишите в переменную text.\n",
        "import numpy as np\n",
        "\n",
        "res = ''\n",
        "print(type(res))\n",
        "for line in text:\n",
        "  res += line\n",
        "text = res.lower()\n",
        "\n",
        "\n",
        "\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('Отлично!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "Отлично!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2nqJuiZmvg",
        "colab_type": "text"
      },
      "source": [
        "Выделите множество всех символов, с которыми нам довелось встретиться в переменную `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwRBXqgvZmvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB7p-woUZmvj",
        "colab_type": "text"
      },
      "source": [
        "Постройте словарь `token_to_idx` вида <символ>: <индекс> и словарь `idx_to_token` вида <индекс>: <символ>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHdrI1vKZmvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# словарь вида <индекс>:<символ>\n",
        "token_to_idx = {}\n",
        "i = 0\n",
        "for symbol in tokens:\n",
        "  token_to_idx[symbol] = i\n",
        "  i += 1\n",
        "\n",
        "# словарь вида <символ>:<индекс>\n",
        "idx_to_token = {y:x for x,y in token_to_idx.items()}\n",
        "\n",
        "num_tokens = len(tokens) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZKsWESZmvl",
        "colab_type": "text"
      },
      "source": [
        "*Комментарий: т.к. у нас всего 38 различных токенов, в этот раз воспользуемся one-hot encoding'ом.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA_X-7HxZmvm",
        "colab_type": "text"
      },
      "source": [
        "## Построение модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOzizWkuZmvm",
        "colab_type": "text"
      },
      "source": [
        "Теперь наша задача - создать и обучить рекуррентную нейронную сеть, которая сможет генерировать что-то похожее на поэзию Шекспира.\n",
        "\n",
        "Для начала воспользуемся классической RNN, аналогичной построенной на семинаре. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGc9GolUZmvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqYz1UvvaopD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNNLoop(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, _ = self.rnn(self.emb(x))\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp\n",
        "    \n",
        "model = CharRNNLoop()\n",
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKj4XFvHlZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_size=32\n",
        "batch_size=16\n",
        "\n",
        "\n",
        "idx_text = [token_to_idx[w] for w in text]\n",
        "num_batches = len(idx_text) // (seq_size * batch_size)\n",
        "in_text = idx_text[:num_batches * batch_size * seq_size]\n",
        "out_text = np.zeros_like(in_text)\n",
        "out_text[:-1] = in_text[1:]\n",
        "out_text[-1] = in_text[0]\n",
        "\n",
        "in_text = np.reshape(in_text, (batch_size, -1))\n",
        "out_text = np.reshape(out_text, (batch_size, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OObI5v7fK86L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_text = torch.LongTensor(in_text)\n",
        "logp_seq = model(in_text)\n",
        "\n",
        "loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n",
        "                  in_text[:, :-1].contiguous().view(-1))\n",
        "\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqGTK7jdLurC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f2d92fb-85c5-4218-a031-03b245ea3c3a"
      },
      "source": [
        "in_text.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 6240])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn-W9A-iLQ2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "64e5e020-a993-4ea7-adb0-ff8a6f2e5d67"
      },
      "source": [
        "history = []\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(200000):\n",
        "    i = random.randint(0, num_batches)\n",
        "    batch_ix = in_text[:, i:i+seq_size]\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    # print(batch_ix.size())\n",
        "    logp_seq = model(batch_ix)\n",
        "\n",
        "\n",
        "    \n",
        "    # compute loss\n",
        "\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    \n",
        "    \n",
        "    # train with backprop\n",
        "\n",
        "    logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "    loss = -logp_next.mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "        torch.save(opt.state_dict(), 'optimizer.pth')\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIJ6v8DokHBlUxRgywAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edfg2eheZmvo",
        "colab_type": "text"
      },
      "source": [
        "Постройте график функции потерь в зависимости от номера эпохи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFrcuutcZmvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Пример сгенерированного текста. Функция `generate_text` отсутствует в коде выше. Реализуйте ее самостоятельно.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g36f9CKXcuJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(length, initial = ' ', temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in initial]\n",
        "    \n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).unsqueeze(0)\n",
        "    #print( x_sequence.data.numpy()[0])\n",
        "\n",
        "\n",
        "    #start generating\n",
        "    for _ in range(length):\n",
        "\n",
        "\n",
        "        # NOTE THAT  x_sequence[ :, -1] is NOT the last symbol, it's the whole sequence\n",
        "        # u can easily check it with print fuction\n",
        "        # it is used to reduce dimention\n",
        "\n",
        "\n",
        "        logp_next = model(x_sequence[ :, -1])\n",
        "        #print( x_sequence.data.numpy()[0]) \n",
        "        #print( x_sequence[ :, -1].data.numpy()[0]) \n",
        "        \n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0][-1]\n",
        "\n",
        "        #print(str(p_next)+ '\\n' )\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p = p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        #print( x_sequence.data.numpy()[0]) \n",
        "        x_sequence = torch.cat([x_sequence[:, -1], next_ix], dim=1)\n",
        "        x_sequence = x_sequence.unsqueeze(0)\n",
        "    \n",
        "    #print( x_sequence.data.numpy()[0]) \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0][0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCJOwReeSdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23f4b436-ada1-4655-8382-297e7a62af90"
      },
      "source": [
        "generate_text(length=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" may, yet not directly th praintond in of thy praise thee?\\n  even for this shall have xvi\\n\\n  thin the se healter heir mind:\\n  shall hate be fairer lodg'd than gentle lovery'sprogn,\\n  when beauty lived and deen my will beautiful old rime,\\n  in praise of ladies dead and lovely knights,\\n  then, in the blazon of sweet beauty's best,\\n  of hand, of everyoot, of holth not both to evel,\\n  within the gentle closure of lade,  of at,\\n  ecoue thiners beauty's but being both from me, in the blazon of sweet be\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0hnwfDdZmvr",
        "colab_type": "text"
      },
      "source": [
        "### Более поэтичная модель\n",
        "\n",
        "Теперь давайте воспользуемся LSTM слоем вместо классической RNN и сравним результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n62P2O7MZmvs",
        "colab_type": "text"
      },
      "source": [
        "Снова постройте график функции потерь от числа эпох. Стал ли финальный loss лучше?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w84HJNMZmvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharLSTMLoop(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, _ = self.lstm(self.emb(x))\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp\n",
        "    \n",
        "model = CharLSTMLoop()\n",
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5XXfWj8aXbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_size=32\n",
        "batch_size=16\n",
        "\n",
        "\n",
        "idx_text = [token_to_idx[w] for w in text]\n",
        "num_batches = len(idx_text) // (seq_size * batch_size)\n",
        "in_text = idx_text[:num_batches * batch_size * seq_size]\n",
        "out_text = np.zeros_like(in_text)\n",
        "out_text[:-1] = in_text[1:]\n",
        "out_text[-1] = in_text[0]\n",
        "\n",
        "in_text = np.reshape(in_text, (batch_size, -1))\n",
        "out_text = np.reshape(out_text, (batch_size, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2zNuFJkaetV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cff7dfd2-9302-4a5b-c7ec-27d922e73394"
      },
      "source": [
        "history = []\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(200000):\n",
        "    i = random.randint(0, num_batches)\n",
        "    batch_ix = in_text[:, i:i+seq_size]\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    # print(batch_ix.size())\n",
        "    logp_seq = model(batch_ix)\n",
        "\n",
        "\n",
        "    \n",
        "    # compute loss\n",
        "\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    \n",
        "    \n",
        "    # train with backprop\n",
        "\n",
        "    logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "    loss = -logp_next.mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        torch.save(model.state_dict(), 'model_lstm.pth')\n",
        "        torch.save(opt.state_dict(), 'optimizer_lstm.pth')\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"LSTM didn't converge.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwl1EJAcp3EVEcpDCXUQkByncRURy0P8HIB/tl9Lhz5QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQrLYnmnj_x",
        "colab_type": "text"
      },
      "source": [
        "Видим по графику, что лосс стал  меньше, также он убывает гораздо быстрее, чем в случае RNN. Можно было обучать меньшее число эпох, т.к. лосс вышел на стационарынй уровень на ~ 75000 итерации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxbT09_sZmvt",
        "colab_type": "text"
      },
      "source": [
        "Сгенерируйте текст с помощью обученной сети для различных значений параметра `temperature`: `[0.1, 0.2, 0.5, 1.0, 2.0]` (\"температуры\" при генерации). Оцените результаты визуально, попробуйте их проинтерпретировать."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb4KGWinmyfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "b56cf694-6e18-4d5c-e06a-06aaeadeeaa2"
      },
      "source": [
        "generate_text(length=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 14 29 16 12 31 32 29 16 30  1 34 16  1 15 16 30 20 29 16  1 20 25 14\n",
            "  29 16 12 30 16  6  0  1  1 31 19 12 31  1 31 19 16 29 16 13 36  1 13 16\n",
            "  12 32 31 36  3 30  1 29 26 30 16  1 24 20 18 19 31  1 25 16 33 16 29  1\n",
            "  15 20 16  6  0  1  1 13 32 31  1 12 30  1 31 19 16  1 29 20 27 16 29  1\n",
            "  30 19 26 32 23 15  1 13 36  1 31 20 24 16  1 15 16 14 16 12 30 16  6  0\n",
            "   1  1 19 20 30  1 31 16 25 15 16 29  1 19 16 20 29  1 24 20 18 19 31  1\n",
            "  13 16 12 29  1 19 20 30  1 24 16 24 26 29 36  9  0  1  1 13 32 31  1 31\n",
            "  19 26 32  6  1 14 26 25 31 29 12 14 31 16 15  1 31 26  1 31 19 20 25 16\n",
            "   1 26 34 25  1 13 29 20 18 19 31  1 16 36 16 30  6  0  1  1 17 29 26 24\n",
            "   1 34 19 16 25 14 16  1 12 31  1 27 23 16 12 30 32 29 16  1 31 19 26 32\n",
            "   1 24 12 36 30 31  1 14 26 24 16  1 12 25 15  1 27 12 29 31  1 26 17  1\n",
            "  24 16 11  0  1  1 34 19 12 31  1 14 12 25  1 24 20 25 16  1 26 34 25  1\n",
            "  27 29 12 20 30 16  1 31 26  1 24 20 25 16  1 26 34 25  1 30 16 23 17  1\n",
            "  13 29 20 25 18 11  0  1  1 12 25 15  1 34 19 12 31  1 20 30  3 15  1 31\n",
            "  19 16 16  1 12 29 16  1 12 23 23  1 15 16 31 16 29 24 20 25 12 31 16  8\n",
            "   0  1  1 17 26 29  1 19 26 34  1 15 26  1 20  1 19 26 23 15  1 31 19 16\n",
            "  16  1 13 32 31  1 13 36  1 31 19 36  1 18 29 12 25 31 20 25 18 11  0  1\n",
            "   1 12 25 15  1 17 26 29  1 31 19 12 31  1 29 20 14 19 16 30  1 34 19 16\n",
            "  29 16  1 20 30  1 24 36  1 15 16 30 16 29 33 20 25 18 11  0  1  1 31 19\n",
            "  16  1 14 12 32 30 16  1 26 17  1 31 19 20 30  1 17 12 20 29  1 18 20 17\n",
            "  31 10  0  1  1 13 32 31  1 25 26 31  1 15 20 29 16 14 31 23 36]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" creatures we desire increase,\\n  that thereby beauty's rose might never die,\\n  but as the riper should by time decease,\\n  his tender heir might bear his memory:\\n  but thou, contracted to thine own bright eyes,\\n  from whence at pleasure thou mayst come and part of me?\\n  what can mine own praise to mine own self bring?\\n  and what is'd thee are all determinate.\\n  for how do i hold thee but by thy granting?\\n  and for that riches where is my deserving?\\n  the cause of this fair gift;\\n  but not directly\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHNdaL9WnfV0",
        "colab_type": "text"
      },
      "source": [
        "Сгенерированный текст стал более осмысленным, практически не осталось ошибок в словах, при желании можно даже найти какой-то смысл:)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsTZ-mkyZmvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a453dd1-9611-4fa6-b56a-9e6a8e962c8e"
      },
      "source": [
        "for temp in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "  print('temperature =' + str(temp) + '\\n' + str(generate_text(length=500, temperature = temp)) + '\\n')\n",
        "  print('__________________________________________________________')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "temperature =0.1\n",
            " thou lead away,\n",
            "  if thou wouldst use the strength of all thy state!\n",
            "    but do not so; i love thee in such sort,\n",
            "    as, thou being mine, mine is thy good report.\n",
            "\n",
            "  xcvii\n",
            "\n",
            "  hefut neter part of me?\n",
            "  what can mine own praise to mine own self bring?\n",
            "  and what is't but mine own when i praise thee?\n",
            "  even for this, let us divided live,\n",
            "  and our dear lovel deter at being at your beck,\n",
            "  the imprison'd absence of your least;\n",
            "  yet in these thoughts my self almost despising,\n",
            "  haply i think on the\n",
            "\n",
            "__________________________________________________________\n",
            "temperature =0.2\n",
            " the prey of every vulgar thief.\n",
            "  thee have i not lock'd up in any chest,\n",
            "  save where thou art not, though i feel thou art,\n",
            "  within the gentle closure of my breast,\n",
            "  from whence at pleasure thou mayst come and part of me?\n",
            "  what can mine own praise to mine own self bring?\n",
            "  and what is't but mine own when i praise thee?\n",
            "  even for this, let us divided live,\n",
            "  and our dear love will is noth any come then might i not say so,\n",
            "    to give full growth to that which still doth grow?\n",
            "\n",
            "  cxvi\n",
            "\n",
            "  let \n",
            "\n",
            "__________________________________________________________\n",
            "temperature =0.5\n",
            " manners may i sing,\n",
            "  when thou art all the better part of me?\n",
            "  what can mine own praise to mine own self bring?\n",
            "  and what is't but mine own when i praise thee?\n",
            "  even for this, let us divided live,\n",
            "  and our dear love will is noth any come then my state!\n",
            "    but do not so; i love thee in such sort,\n",
            "    as, thou being mine, mine is thy good report.\n",
            "\n",
            "  xcvii\n",
            "\n",
            "  hefut neter at livery vulgar thief.\n",
            "  thee have i not lock'd up in any chest,\n",
            "  save where thou art not, though i feel thou art,\n",
            "  with\n",
            "\n",
            "__________________________________________________________\n",
            "temperature =1.0\n",
            " woman's face with nature's own hand painted,\n",
            "  hast thou, the master mistress of my passion;\n",
            "  a woman's gentle heart, but not acquainted\n",
            "  with shifting change, as is false women's fainted,\n",
            "  hate save where thou art not, though i feel thou art,\n",
            "  within the gentle closure of praise of ladies dead and lovely knights,\n",
            "  then, in the blazon of sweet beauty's best,\n",
            "  of hand, of foot, of lip, of eye, of brow,\n",
            "  i see their antique pen would have express'd\n",
            "  even spising,\n",
            "  haply i think on thee,--\n",
            "\n",
            "__________________________________________________________\n",
            "temperature =2.0\n",
            " hest,\n",
            "   in days long tiqhes my will in thin's your tele,\n",
            "  as thy presence is, gracious of days out in these thoughts my self almoste,\n",
            "   in thour thee,-- and then my ming owthts'd from whence at love thee in such sort,\n",
            "    as, thou being mine, mine is mdising,\n",
            "  whell diee ead and lovey and knot min'k dinder, being at leald rine?\n",
            "  wich ist days'd part ne'er know, bobut thou, in theser veey deraintend,\n",
            "  or to thyself at least, tikn save be in any commn a, before tith nange my mind:\n",
            "  shall ha\n",
            "\n",
            "__________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzqHIGl0Zmvu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   LSTM работает лучше обычной CNN\n",
        "*   Чем больше температура, тем больше случайность. Поэтому при temp = 2.0, текст уже перестает быть понятным, некоторые слова хоть и похожи на настоящие, но таковыми не являются.\n",
        "*   При temp = 1  получилось самое осмысленное стихотворение\n",
        "*   Из-за того, что в датасете была нумерация страниц, модели генерят и ее.\n",
        "*   Работу моих CNN и LSTM можно ускорить: не обрабатовать последовательность на каждой итерации, а выдавать и передавать на следущую итерацию хидден. Тогда можно подавать лишь последний элемент последовательности (вместе с хидденом). \n",
        "\n",
        "### Сделаем LSTM с передаей хиденна.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHZdR76IP7AO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharLSTMLoop_hidden(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size, rnn_num_units, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        self.hidden_dim = rnn_num_units\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, hidden = self.lstm(self.emb(x), hidden)\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp, hidden \n",
        "        \n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(1, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(1, batch_size, self.hidden_dim).zero_())\n",
        "        return hidden\n",
        "    \n",
        "model = CharLSTMLoop_hidden()\n",
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAQXo3HydMsN",
        "colab": {}
      },
      "source": [
        "seq_size=32\n",
        "batch_size=16\n",
        "\n",
        "\n",
        "idx_text = [token_to_idx[w] for w in text]\n",
        "num_batches = len(idx_text) // (seq_size * batch_size)\n",
        "in_text = idx_text[:num_batches * batch_size * seq_size]\n",
        "out_text = np.zeros_like(in_text)\n",
        "out_text[:-1] = in_text[1:]\n",
        "out_text[-1] = in_text[0]\n",
        "\n",
        "in_text = np.reshape(in_text, (batch_size, -1))\n",
        "out_text = np.reshape(out_text, (batch_size, -1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIxleYsJd7PI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "45c76d0c-e75a-4cc7-a766-7f0995276441"
      },
      "source": [
        "history = []\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "h = model.init_hidden(batch_size)\n",
        "for i in range(50000):\n",
        "    i = random.randint(0, num_batches)\n",
        "    batch_ix = in_text[:, i:i+seq_size]\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    # print(batch_ix.size())\n",
        "    #h.detach_()\n",
        "    h = tuple([e.data for e in h])\n",
        "\n",
        "\n",
        "    logp_seq, h = model(batch_ix, h)\n",
        "\n",
        "\n",
        "    \n",
        "    # compute loss\n",
        "\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    \n",
        "    \n",
        "    # train with backprop\n",
        "\n",
        "    logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "    loss = -logp_next.mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        torch.save(model.state_dict(), 'model_lstm_hidden.pth')\n",
        "        torch.save(opt.state_dict(), 'optimizer_lstm_hidden.pth')\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"LSTM didn't converge.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nksz/B1aOR4zvlTLMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuT4_vrckyF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text_hidden(length, initial = ' ', temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in initial]\n",
        "    \n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).unsqueeze(0)\n",
        "    \n",
        "    h = model.init_hidden(1)\n",
        "\n",
        "    #start generating\n",
        "    for _ in range(length):\n",
        "\n",
        "        #________________________________\n",
        "        # NOTE THAT  x_sequence[ :, :, -1] IS the last symbol of the sequence\n",
        "        # u can easily check it with print fuction\n",
        "        #________________________________\n",
        "\n",
        "        h = tuple([e.data for e in h])\n",
        "\n",
        "        logp_next, h = model(x_sequence[ :, :, -1], h)\n",
        "       \n",
        "        #print( x_sequence[ :, :, -1].data.numpy()) \n",
        "        \n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0][-1]\n",
        "\n",
        "        #print(str(p_next)+ '\\n' )\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p = p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        " \n",
        "        x_sequence = torch.cat([x_sequence[:, -1], next_ix], dim=1)\n",
        "        x_sequence = x_sequence.unsqueeze(0)\n",
        "        #print('_______END_OF_CURRENT_ITER_____________')\n",
        "    \n",
        "    \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0][0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Gi1yHnkyMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "26ae40f5-9158-4b48-ac76-7186892a128e"
      },
      "source": [
        "generate_text_hidden(length = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" i not rost despe,\\n  but do not so; in swhee i  i  art not, though i feel thou art,\\n  within the gentle closure of my bre is my deserving?\\n  then my state,\\n  like to the lark at blazon ofour,\\n  hand the account of hours to crack,\\n  the imprison'd wivef lip, of eyt,\\n  or to thyself at least kind-hearted prove:\\n    make thee another self bring?\\n  and what is't but mine own when i praise thee?\\n  even fi hold bue may i sing,\\n  hand spacious,\\n  notod let us dom me, both to each friend,\\n  i guess one a\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPSqg2Cr0iPm",
        "colab_type": "text"
      },
      "source": [
        "По ощущуениям стало работать быстрее. \n",
        "\n",
        "К сожалению, не усе"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yu_dFmuZmvv",
        "colab_type": "text"
      },
      "source": [
        "#### Сохранение и загрузка модели\n",
        "\n",
        "Сохраните обученную модель на диск, затем загрузите ее и сгенерируйте текст. Примеры доступны по [ссылке](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii-dcPK3ry2A",
        "colab_type": "text"
      },
      "source": [
        "Заметим, что я сохраняю модель на каждом тесте. Загрузим RNN из первого пункта лабы и сгенерируем текст с помощью этой модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8v8rlfgZmvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "163f1a2e-2ffa-4eab-d2a5-ec7a13cad2d8"
      },
      "source": [
        "model = CharRNNLoop()\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "model.eval()\n",
        "\n",
        "generate_text(length=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" shalt chis.\\n\\n  lxviind\\n  those children nursed, deliver'd from thy brain,\\n  to take a new acquaintance of thy mind.\\n\\n   but do not so; i love thee in such sort,\\n    no; let me suffer, being at your beck,\\n  the imprison'd abs thy progk on thee,-- and then my state,\\n  like to the lark at break of day arising\\n  no; your tich still doth grow?\\n\\n  cxvi\\n\\n  this, gracious and kind,\\n  or to thyself arncinds ilh an of thy to live,\\n  lip, of eye, of brow,\\n  i should pain,\\n  wart,\\n  sut nuty vand thut hish \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpRrIYUFZmvv",
        "colab_type": "text"
      },
      "source": [
        "Данная часть задания завершена."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YsCndrEZmvw",
        "colab_type": "text"
      },
      "source": [
        "#### Полезные ссылки\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Статья Андрея Карпатого про RNN. </a> В качестве примеров рассматриваются задачи генерации Шекспировских текстов, Latex формул, Linux Source Code и детских имен.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Репозиторий с кодом по char-rnn </a> (тоже за авторством Андрея Карпатого)\n",
        "3. Полезный репозиторий по PyTorch: [ссылка](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}